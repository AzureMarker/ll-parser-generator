use crate::lexer::Token;
use std::ops::Range;

grammar<'input>;

// Example grammar file:
// use some::imports;
//
// token Token {
//     "STR_ALIAS" => Token::MyToken
// }
//
// grammar;
//
// Nonterminal: TheType = {
//     some symbols here "STR_ALIAS" => action code here,
//     second production here => second action here,
// };

pub Grammar = Imports TokenDecl GrammarDecl Nonterminals;

Imports: () = ("use" <"IMPORT_CODE"> ";")* => ();

TokenDecl: () = "token" "{" "}" => ();

GrammarDecl = "grammar" ";";

Nonterminals = "token";

extern {
    type Location = usize;
    type Error = Range<usize>;

    enum Token<'input> {
        "IDENT" => Token::Identifier(<&'input str>),
        "IMPORT_CODE" => Token::ImportCode(<&'input str>),
        "CODE" => Token::Code(<&'input str>),
        "grammar" => Token::Grammar,
        "token" => Token::Token,
        "use" => Token::Use,
        "{" => Token::LBrace,
        "}" => Token::RBrace,
        ";" => Token::Semicolon,
        ":" => Token::Colon,
        "=>" => Token::EqArrow,
        "=" => Token::Equal,
        "," => Token::Comma,
        ")" => Token::RParen,
        "(" => Token::LParen,
        "[" => Token::LBracket,
        "]" => Token::RBracket,
        "|" => Token::VBar
        }
}